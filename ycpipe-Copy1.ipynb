{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "dj.config['external'] = dict(\n",
    "              protocol='file',\n",
    "              location = '/')\n",
    "# external storage place\n",
    "\n",
    "from pipeline import reso\n",
    "from pipeline import experiment\n",
    "from pipeline import mice\n",
    "from pipeline import  notify, shared\n",
    "import scanreader\n",
    "from datajoint.jobs import key_hash\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pipeline.utils import galvo_corrections, signal, quality, mask_classification, performance\n",
    "from pipeline.exceptions import PipelineException\n",
    "import os\n",
    "import time\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from pipeline.exceptions import PipelineException\n",
    "from pipeline.utils.signal import mirrconv\n",
    "import tifffile\n",
    "import cv2\n",
    "dj.conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchtable=dj.schema(\"yizhou_patch\",locals(),create_tables=True)\n",
    "\n",
    "#right arm, about patch only\n",
    "\n",
    "@patchtable\n",
    "class PatchSession(dj.Manual): \n",
    "    definition = \"\"\" \n",
    "        -> mice.Mice    \n",
    "        patch_session:int #session is different from reso session.\n",
    "        ---\n",
    "        # session here is one experiment, most likely, in one day.\n",
    "        folder='':varchar(256) # the path to the folder that contains file of the cell.\n",
    "        \"\"\"\n",
    "@patchtable\n",
    "class Cell(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    -> PatchSession #include animal id etc, patch session.\n",
    "    ---\n",
    "    notes='':varchar(256) # the notes about the cell. \n",
    "    # where does the dates etc go? notes?\n",
    "    \"\"\"\n",
    "@patchtable\n",
    "class Recording(dj.Manual): \n",
    "    definition = \"\"\"\n",
    "    -> Cell #include animal id etc, patch session, notes about the cell.\n",
    "    ---\n",
    "    filename='':varchar(256) \n",
    "    i1:external\n",
    "    command:external\n",
    "    vm:external\n",
    "    frametimes:external\n",
    "    ephystimes:external\n",
    "    igain:int\n",
    "    vgain:int\n",
    "    ilowpass:int\n",
    "    vlowpass:int\n",
    "    vhighpass:int\n",
    "\n",
    "    \"\"\"\n",
    "@patchtable\n",
    "class Patchspikes(dj.Manual):\n",
    "    definition = \"\"\" \n",
    "        -> Recording #which has animal, patch session, notes, raw file, setting, data.\n",
    "        ---\n",
    "        spike_ts:external # timestamps. on same clock as trace.\n",
    "        \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#left arm, about imaging only\n",
    "\n",
    "@patchtable\n",
    "class Scaninfo(dj.Manual):\n",
    "    definition = \"\"\"   \n",
    "    # those will be cp from reso.scaninfo, but only contain 1 entry\n",
    "    animal_id:int\n",
    "    session:int\n",
    "    scan_idx:int\n",
    "    pipe_version:int\n",
    "    field:int #from correctionchannel.  field was a prim key\n",
    "    ---\n",
    "    #\n",
    "    nfields                 : tinyint           # number of fields\n",
    "    nchannels               : tinyint           # number of channels\n",
    "    nframes                 : int               # number of recorded frames\n",
    "    nframes_requested       : int               # number of requested frames (from header)\n",
    "    px_height               : smallint          # lines per frame\n",
    "    px_width                : smallint          # pixels per line\n",
    "    um_height               : float             # height in microns\n",
    "    um_width                : float             # width in microns\n",
    "    x                       : float             # (um) center of scan in the motor coordinate system\n",
    "    y                       : float             # (um) center of scan in the motor coordinate system\n",
    "    fps                     : float             # (Hz) frames per second\n",
    "    zoom                    : decimal(5,2)      # zoom factor\n",
    "    bidirectional           : boolean           # true = bidirectional scanning\n",
    "    usecs_per_line          : float             # microseconds per scan line\n",
    "    fill_fraction           : float             # raster scan temporal fill fraction (see scanimage)\n",
    "    valid_depth       : boolean           # whether depth has been manually check\n",
    "    # above cp from reso.scaninfo\n",
    "    channel:int  # from reso.correctionchannel, just one value so place it here.\n",
    "    z:float # from scaninfo.field.\n",
    "    delay_image:longblob #from scaninfo.field\n",
    "    \n",
    "    \"\"\"    \n",
    "        \n",
    "@patchtable\n",
    "class Segmentationtask(dj.Manual):\n",
    "    definition = \"\"\" # defines the target of segmentation and the channel to use\n",
    "    -> experiment.Scan\n",
    "    -> shared.Field\n",
    "    -> shared.Channel\n",
    "    -> shared.SegmentationMethod\n",
    "    ---\n",
    "    -> experiment.Compartment\n",
    "    \"\"\"\n",
    "    def fill(self, key, channel=1, segmentation_method=6, compartment='soma'):\n",
    "        for field_key in (Field() & key).fetch(dj.key):\n",
    "            tuple_ = {**field_key, 'channel': channel, 'compartment': compartment,\n",
    "                      'segmentation_method': segmentation_method}\n",
    "            self.insert1(tuple_, ignore_extra_fields=True, skip_duplicates=True)\n",
    "    def estimate_num_components(self):\n",
    "        \"\"\" Estimates the number of components per field using simple rules of thumb.\n",
    "\n",
    "        For somatic scans, estimate number of neurons based on:\n",
    "        (100x100x100)um^3 = 1e6 um^3 -> 100 neurons; (1x1x1)mm^3 = 1e9 um^3 -> 100K neurons\n",
    "\n",
    "        For axonal/dendritic scans, just ten times our estimate of neurons.\n",
    "\n",
    "        :returns: Number of components\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        # Get field dimensions (in microns)\n",
    "        scan = (Scaninfo() & self & {'pipe_version': CURRENT_VERSION})\n",
    "        field_height, field_width = scan.fetch1('um_height', 'um_width')\n",
    "        field_thickness = 10  # assumption\n",
    "        field_volume = field_width * field_height * field_thickness\n",
    "        # Estimate number of components\n",
    "        compartment = self.fetch1('compartment')\n",
    "        if compartment == 'soma':\n",
    "            num_components = field_volume * 0.0001\n",
    "        elif compartment == 'axon':\n",
    "            num_components = field_volume * 0.0005  # five times as many neurons\n",
    "        elif compartment == 'bouton':\n",
    "            num_components = field_volume * 0.001   # 10 times as many neurons\n",
    "        else:\n",
    "            PipelineException(\"Compartment type '{}' not recognized\".format(compartment))\n",
    "        return int(round(num_components))\n",
    "    \n",
    "        \n",
    "@patchtable\n",
    "class Rastercorrection(dj.Computed):\n",
    "    definition = \"\"\" \n",
    "                             # animal_id, session, scan_idx, version\n",
    "    -> Scaninfo\n",
    "    # need correction channel, now the correction channel channel is in scaninfo as col, not an independent table.\n",
    "    # now using the first channel to correct, normally its the green channel.\n",
    "    ---\n",
    "    raster_template     : longblob      # average frame from the middle of the movie\n",
    "    raster_phase        : float         # difference between expected and recorded scan angle\n",
    "    \"\"\"    \n",
    "    def make(self, key):\n",
    "        from scipy.signal import tukey\n",
    "        # Read the scan\n",
    "        fps=(Scaninfo() & key).fetch1('fps')\n",
    "        print(\"fps is \",fps)\n",
    "        scan_filename = (experiment.Scan() & key).local_filenames_as_wildcard\n",
    "        print(scan_filename)\n",
    "        print(scanreader.core.expand_wildcard(scan_filename))\n",
    "        scan = scanreader.read_scan(scan_filename, dtype=np.float32)\n",
    "        # Select correction channel\n",
    "        channel =  (Scaninfo()&key).fetch1('channel')-1\n",
    "        print(key)\n",
    "        field_id = key['field'] - 1\n",
    "        # Load some frames from the middle of the scan\n",
    "        middle_frame =  int(np.floor(scan.num_frames / 2))\n",
    "        frames = slice(max(middle_frame - int(60*fps), 0), middle_frame + int(60*fps))\n",
    "        startts=time.time()\n",
    "        import tifffile\n",
    "        scan_filename=scanreader.core.expand_wildcard(scan_filename)[0]\n",
    "        # one recording session has one tiff\n",
    "        f=tifffile.TiffFile(scan_filename)\n",
    "        a=f.asarray(frames)\n",
    "        print('pipe, a shape,', a.shape)\n",
    "        mini_scan=np.moveaxis(a,0,2) #(f,x,y) to (y,x,f)\n",
    "        print('pipe, mini_scan shape t1,', mini_scan.shape)\n",
    "        mini_scan = mini_scan.astype(np.float32, copy=False)\n",
    "#         mini_scan = scan[field_id, :, :, channel, frames]\n",
    "        print('the time takes to get miniscan is:')\n",
    "        print(time.time()-startts)\n",
    "        # Create results tuple\n",
    "        tuple_ = key.copy()\n",
    "        # Create template (average frame tapered to avoid edge artifacts)\n",
    "        taper = np.sqrt(np.outer(tukey(scan.image_height, 0.4),\n",
    "                                 tukey(scan.image_width, 0.4)))\n",
    "        anscombed = 2 * np.sqrt(mini_scan - mini_scan.min() + 3 / 8)  # anscombe transform\n",
    "        template = np.mean(anscombed, axis=-1) * taper\n",
    "        tuple_['raster_template'] = template\n",
    "        # Compute raster correction parameters\n",
    "        if scan.is_bidirectional:\n",
    "            tuple_['raster_phase'] = galvo_corrections.compute_raster_phase(template,\n",
    "                                                         scan.temporal_fill_fraction)\n",
    "        else:\n",
    "            tuple_['raster_phase'] = 0\n",
    "        # Insert\n",
    "        self.insert1(tuple_)\n",
    "    def get_correct_raster(self):\n",
    "        \"\"\" Returns a function to perform raster correction on the scan. \"\"\"\n",
    "        raster_phase = self.fetch1('raster_phase')\n",
    "        fill_fraction = (Scaninfo() & self).fetch1('fill_fraction')\n",
    "        if abs(raster_phase) < 1e-7:\n",
    "            correct_raster = lambda scan: scan.astype(np.float32, copy=False)\n",
    "        else:\n",
    "            correct_raster = lambda scan: galvo_corrections.correct_raster(scan,\n",
    "                                                             raster_phase, fill_fraction)\n",
    "        return correct_raster\n",
    "\n",
    "        \n",
    "        \n",
    "@patchtable\n",
    "class  Motioncorrection(dj.Computed):\n",
    "    definition = \"\"\" \n",
    "        ->Rastercorrection\n",
    "        ---\n",
    "        motion_template                 : longblob      # image used as alignment template\n",
    "        y_shifts                        : longblob      # (pixels) y motion correction shifts\n",
    "        x_shifts                        : longblob      # (pixels) x motion correction shifts\n",
    "        y_std                           : float         # (pixels) standard deviation of y shifts\n",
    "        x_std                           : float         # (pixels) standard deviation of x shifts\n",
    "        outlier_frames                  : longblob      # mask with true for frames with outlier shifts (already corrected)\n",
    "        align_time=CURRENT_TIMESTAMP    : timestamp     # automatic\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        \"\"\"Computes the motion shifts per frame needed to correct the scan.\"\"\"\n",
    "        from scipy import ndimage\n",
    "        from pipeline.utils import galvo_corrections, signal, quality, mask_classification, performance\n",
    "        import pyfftw\n",
    "        from imreg_dft import utils\n",
    "        import numpy as np\n",
    "        from scipy import interpolate  as interp\n",
    "        from scipy import signal\n",
    "        from scipy import ndimage\n",
    "        import tifffile\n",
    "        # Read the scan\n",
    "        scan_filename = (experiment.Scan() & key).local_filenames_as_wildcard\n",
    "        scan = scanreader.read_scan(scan_filename)\n",
    "        # Get some params\n",
    "        px_height, px_width = (Scaninfo() & key).fetch1('px_height', 'px_width')\n",
    "        channel = (Scaninfo() & key).fetch1('channel') - 1\n",
    "        fps=(Scaninfo() & key).fetch1('fps')\n",
    "        field_id = key['field'] - 1\n",
    "        # Load some frames from middle of scan to compute template\n",
    "        skip_rows = int(round(px_height * 0.10))  \n",
    "        # we discard some rows/cols to avoid edge artifacts\n",
    "        # so actually the motion correction is only looking at the center 80%\n",
    "        # tested zero padding instead of taper, similar results\n",
    "        # zero padding can preserve more data, use full mini scan \n",
    "        # taper is applied to mini scan, so less data than miniscan\n",
    "        # i guess best way is to apply taper to full scan, than zero pad\n",
    "        skip_cols = int(round(px_width * 0.10))\n",
    "        middle_frame = int(np.floor(scan.num_frames / 2))\n",
    "        fromframe=int(max(middle_frame - 100*fps, 0))\n",
    "        toframe=int(middle_frame + 100*fps)\n",
    "        print(\"gettign the frames in between \",fromframe,toframe)\n",
    "        starttime=time.time()\n",
    "        scan_filename=scanreader.core.expand_wildcard(scan_filename)[0]\n",
    "        nchan=(Scaninfo()&key).fetch1('nchannels')\n",
    "        correct_raster = (Rastercorrection() & key).get_correct_raster()\n",
    "        # one recording session has one tiff\n",
    "        f=tifffile.TiffFile(scan_filename)\n",
    "        wholescan=f.asarray()# its the full scan\n",
    "        wholescan=np.moveaxis(wholescan,0,2)#(f,x,y) to (y,x,f)\n",
    "        # if there are multi channels, use the first channle (green)\n",
    "        if nchan!=1:\n",
    "            wholescan=wholescan[:,:,::nchan]\n",
    "            # the channel frames are interlaved. green and red channel.\n",
    "            # so ::nch is equal to 0::nch, taking all frames from first ch\n",
    "        wholescan = correct_raster(wholescan)\n",
    "        mini_scan=wholescan[:,:,fromframe:toframe] # now its mini scan temporally\n",
    "        print('pipe, mini_scan shape ,', mini_scan.shape)\n",
    "#         mini_scan=np.swapaxes(a,0,1) #(y,x,f) to (x,y,f)\n",
    "#         print('pipe, mini_scan shape t2,', mini_scan.shape)\n",
    "        mini_scan=mini_scan[skip_rows: -skip_rows, skip_cols: -skip_cols,:] # now its mini both temporally and spatially.\n",
    "#         mini_scan = scan[field_id, skip_rows: -skip_rows, skip_cols: -skip_cols, channel,\n",
    "#                          fromframe:toframe ]\n",
    "        # right now the mini scan is a smaller frame, and only contain frames about several miniutes from the center.\n",
    "        mini_scan = mini_scan.astype(np.float32, copy=False)\n",
    "        # Create template\n",
    "        mini_scan = 2 * np.sqrt(mini_scan - mini_scan.min() + 3 / 8)  # *\n",
    "        template = np.mean(mini_scan, axis=-1)\n",
    "        print('pipe, tem shape,', template.shape)\n",
    "        template = ndimage.gaussian_filter(template, 0.7)  # **\n",
    "        wholescan=wholescan[skip_rows: -skip_rows, skip_cols: -skip_cols,:]#prepare the whole scan into same shape as template.\n",
    "        # * Anscombe tranform to normalize noise, increase contrast and decrease outliers' leverage\n",
    "        # ** Small amount of gaussian smoothing to get rid of high frequency noise\n",
    "        # now, had template\n",
    "        # template is avg of frames from center of scan, both spatially and temporally, with o.7 gaussian smoothed.\n",
    "      \n",
    "        # with the template, start motion correction\n",
    "        ################new parallel, but not improving speed, so not using it#####\n",
    "        #####if consider using it, def a container class based on list, dont use the mp.queue and queue manager.########\n",
    "        \n",
    "#         print('entering mp')\n",
    "#         def ycparallel_motion_shifts(chunks, results, raster_phase, fill_fraction, template):\n",
    "#             \"\"\" Compute motion correction shifts to chunks of scan.\n",
    "#             Function to run in each process. Consumes input from chunks and writes results to\n",
    "#             results. Stops when stop signal is received in chunks.\n",
    "#             :param queue chunks: Queue with inputs to consume.\n",
    "#             :param list results: Where to put results.\n",
    "#             :param float raster_phase: Raster phase used for raster correction.\n",
    "#             :param float fill_fraction: Fill fraction used for raster correction.\n",
    "#             :param np.array template: Template used to compute motion shifts.\n",
    "#             :returns: (frames, y_shifts, x_shifts) tuples.\n",
    "#             \"\"\"\n",
    "#             while True:\n",
    "#                 # Read next chunk (process locks until something can be read)\n",
    "#                 frames, chunk = chunks.get()\n",
    "#                 if chunk is None:  # stop signal when all chunks have been processed\n",
    "#                     return\n",
    "#                 print('template shape ',template.shape)\n",
    "#                 print(time.ctime(), 'Processing frames:', frames)\n",
    "#                 # Correct raster\n",
    "#                 chunk = chunk.astype(np.float32, copy=False)\n",
    "#                 if abs(raster_phase) > 1e-7:\n",
    "#                     chunk = galvo_corrections.correct_raster(chunk, raster_phase, fill_fraction)\n",
    "#                 # Compute shifts\n",
    "#                 y_shifts, x_shifts = yccompute_motion_shifts(chunk, template,\n",
    "#                                                                              num_threads=2)\n",
    "#                 # Add to results\n",
    "#                 results.append((frames, y_shifts, x_shifts))\n",
    "######## end of parallel function. to implent it, same ways as in performance.py###\n",
    "######### start of single thread function.############################\n",
    "        def yccompute_motion_shifts(data,template,method=1, in_place=True, num_threads=8):\n",
    "            \"\"\" Compute shifts in y and x for rigid subpixel motion correction.\n",
    "            :param np.array template: 2-d template image. Each frame in scan is aligned to this.\n",
    "            for the mechanism, search for sub pixel shift/registration based on fft. it is a typical pixel registration method used in motion correction. for information rich image, gives promising results.\n",
    "            \"\"\"\n",
    "            print(data.shape)\n",
    "            # Get some paramsdata\n",
    "            image_height, image_width, num_frames = data.shape\n",
    "            taper = np.outer(signal.tukey(image_height, 0.2), signal.tukey(image_width, 0.2))\n",
    "            taperlarge=(np.outer(signal.tukey(image_height, 0.6), signal.tukey(image_width, 0.6)))\n",
    "            # Prepare fftw\n",
    "            frame = pyfftw.empty_aligned((image_height, image_width), dtype='complex64')\n",
    "            fft = pyfftw.builders.fft2(frame, threads=num_threads, overwrite_input=in_place,\n",
    "                                       avoid_copy=True)\n",
    "            ifft = pyfftw.builders.ifft2(frame, threads=num_threads, overwrite_input=in_place,\n",
    "                                         avoid_copy=True)\n",
    "            # Get fourier transform of template\n",
    "            # print(template.shape)\n",
    "            \n",
    "            #the loop could be parallelized. its the rate limiting step now.\n",
    "            # while the rate limiting step inside it is fft and ifft, which are already parallel.\n",
    "            # check python mechanism of runing these\n",
    "        # for i in range(111,112):\n",
    "            # Compute correlation via cross power spectrum\n",
    "#                 gaussian_k_size=\n",
    "#                 gaussian_mu=0\n",
    "#                 gaussian_sigma=\n",
    "#                 image_freq = fft(\n",
    "#                     np.mean(data[:, :, max(0,int(i-1)):min(num_frames,int(i+1))],2)\n",
    "#                     *1/2\n",
    "#                     +np.mean(data[:, :, max(0,int(i-0.01*fps)):min(num_frames,int(i+0.01*fps))],2)\n",
    "#                     *1/3\n",
    "#                     +np.mean(data[:, :, max(0,int(i-0.1*fps)):min(num_frames,int(i+0.1*fps))],2)\n",
    "#                     *1/6\n",
    "#                     * taper)\n",
    "############ testing methods about windows functions.#######################\n",
    "# for more information, search for window function and sliding window filtering####\n",
    "# the idea is, for this high frequency sampling, single frames have very low snr\n",
    "# think about like we need longger exposer to photo a night sky\n",
    "# thus, using a window function to combine frames together to register is necessray, for sure.\n",
    "# about different window functions. rectangle (simple avergaing) gives a slight enphasize on the center frame in fft. and other window functions could either focus more on the center, or more flat. (search for fft window function)\n",
    "# ideally, we want to correct the center frame so we want focus more on the center\n",
    "# about window size. larger window gives a stablier image, more signal. smaller winodw focus more on the center, but gives a crappy image.\n",
    "# about taking mean or max. i dont have a clear understanding of how the data look at ( should have spent more time on data first ), but seems max gives higher snr in a smaller window. maybe because noise is possion with a smaller max, but signal has a much higher max ( when not firing)\n",
    "# to do, window function/window size/ winodow mean max/preprosess the winodw\n",
    "# preprocess, including smoothing, normalizing, transformations,\n",
    "# mean idea, play with contrast, and try to make different window similar in value\n",
    "# ( first test normalizing the whole data)\n",
    "            if method==1: # using a pretty large rectangle window, with gaussian\n",
    "                template_freq = fft(template * taper).conj() # we only need the conjugate\n",
    "                abs_template_freq = abs(template_freq)\n",
    "                eps = abs_template_freq.max() * 1e-15\n",
    "                # Compute subpixel shifts per image\n",
    "                y_shifts = np.empty(num_frames)\n",
    "                x_shifts = np.empty(num_frames)\n",
    "                starttime=time.time()\n",
    "                for i in range(num_frames):\n",
    "                    theimage=(\n",
    "                    +np.max(data[:, :, max(0,int(i-0.05*fps)):min(num_frames,int(i+0.05*fps))],2)\n",
    "                    *1\n",
    "                    * taper)\n",
    "                    image_freq=fft(ndimage.gaussian_filter(theimage,0.7))\n",
    "                    cross_power = (image_freq * template_freq) / (abs(image_freq) * abs_template_freq + eps)\n",
    "                    shifted_cross_power = np.fft.fftshift(abs(ifft(cross_power)))\n",
    "                    # Get best shift\n",
    "                    shifts = np.unravel_index(np.argmax(taperlarge*shifted_cross_power), shifted_cross_power.shape)\n",
    "                    # here using a larger taper to focus on near shift \n",
    "                    # instead of moving large distance to match the avg frames of block with the template\n",
    "                    #     print(shifts)\n",
    "                    shifts = utils._interpolate(shifted_cross_power, shifts, rad=3)\n",
    "                    # Map back to deviations from center\n",
    "                    y_shifts[i] = shifts[0] - image_height // 2\n",
    "                    x_shifts[i] = shifts[1] - image_width // 2\n",
    "                    if i%10000==0:\n",
    "                        print('now at ',i,time.time()-starttime)\n",
    "                return y_shifts, x_shifts\n",
    "                \n",
    "            elif method==2: # using single frame\n",
    "                template_freq = fft(template * taper).conj() # we only need the conjugate\n",
    "                abs_template_freq = abs(template_freq)\n",
    "                eps = abs_template_freq.max() * 1e-15\n",
    "                # Compute subpixel shifts per image\n",
    "                y_shifts = np.empty(num_frames)\n",
    "                x_shifts = np.empty(num_frames)\n",
    "                starttime=time.time()\n",
    "                for i in range(num_frames):\n",
    "                    theimage = (\n",
    "    #                     np.mean(data[:, :, max(0,int(i-1)):min(num_frames,int(i+1))],2)\n",
    "    #                     *1\n",
    "    #                     +np.mean(data[:, :, max(0,int(i-0.01*fps)):min(num_frames,int(i+0.01*fps))],2)\n",
    "    #                     *1/3\n",
    "    #                     * taper\n",
    "                        (data[:,:,i])\n",
    "                    )\n",
    "                    theimage=(theimage-np.min(theimage))/(np.max(theimage)-np.min(theimage))\n",
    "                    image_freq=fft(ndimage.gaussian_filter(theimage,0.7))\n",
    "    #                     view=np.zeros((image_height, image_width))\n",
    "    #                     for m in range(image_height):\n",
    "    #                         for n in range(image_width):\n",
    "    #                                 view[m,n]=((m-image_height/2)**2+(n-image_width/2)**2)**0.5\n",
    "    #                     view[image_height,image_width]=.9\n",
    "                    cross_power = (image_freq * template_freq) / (abs(image_freq) * abs_template_freq + eps)\n",
    "                    shifted_cross_power = np.fft.fftshift(abs(ifft(cross_power)))\n",
    "                    # Get best shift\n",
    "                    shifts = np.unravel_index(np.argmax(shifted_cross_power), shifted_cross_power.shape)\n",
    "                    # here using a larger taper to focus on near shift \n",
    "                    # instead of moving large distance to match the avg frames of block with the template\n",
    "                    #     print(shifts)\n",
    "                    shifts = utils._interpolate(shifted_cross_power, shifts, rad=3)\n",
    "                    # Map back to deviations from center\n",
    "                    y_shifts[i] = shifts[0] - image_height // 2\n",
    "                    x_shifts[i] = shifts[1] - image_width // 2\n",
    "                    if i%10000==0:\n",
    "                        print('now at ',i,time.time()-starttime)\n",
    "                return y_shifts, x_shifts\n",
    "        \n",
    "            elif method==3: # using zero padding\n",
    "                padwid=3\n",
    "                frame = pyfftw.empty_aligned((image_height+2*padwid, image_width+2*padwid), dtype='complex64')\n",
    "                fft = pyfftw.builders.fft2(frame, threads=num_threads, overwrite_input=in_place,\n",
    "                                       avoid_copy=True)\n",
    "                ifft = pyfftw.builders.ifft2(frame, threads=num_threads, overwrite_input=in_place,\n",
    "                                         avoid_copy=True)\n",
    "                template_freq = fft(np.pad((template),padwid,mode='constant')).conj() # we only need the conjugate\n",
    "                abs_template_freq = abs(template_freq)\n",
    "                eps = abs_template_freq.max() * 1e-15\n",
    "                # Compute subpixel shifts per image\n",
    "                y_shifts = np.empty(num_frames)\n",
    "                x_shifts = np.empty(num_frames)\n",
    "                starttime=time.time()\n",
    "                for i in range(num_frames):\n",
    "                    theimage=(\n",
    "                    +np.max(data[:, :, max(0,int(i-0.025*fps)):min(num_frames,int(i+0.025*fps))],2)\n",
    "                    *1)\n",
    "                    image_freq=fft(ndimage.gaussian_filter(np.pad(theimage,padwid,mode='constant'),0.7))\n",
    "                    cross_power = (image_freq * template_freq) / (abs(image_freq) * abs_template_freq + eps)\n",
    "                    shifted_cross_power = np.fft.fftshift(abs(ifft(cross_power)))\n",
    "                    shifts = np.unravel_index(np.argmax(shifted_cross_power), shifted_cross_power.shape)\n",
    "                    shifts = utils._interpolate(shifted_cross_power, shifts, rad=3)\n",
    "                    y_shifts[i] = shifts[0] - image_height // 2\n",
    "                    x_shifts[i] = shifts[1] - image_width // 2\n",
    "                    if i%10000==0:\n",
    "                        print('now at ',i,time.time()-starttime)\n",
    "                return y_shifts, x_shifts\n",
    "              \n",
    "# add tabs here. im on a old laptop and key registration is different                             y_shifts,x_shifts=yccompute_motion_shifts(thedata,template,method=1, in_place=True, num_threads=8)\n",
    "        '''\n",
    "########################### will only use one window after decide which one is best, implent it here #######################################\n",
    "#                 image_freq = fft(\n",
    "#                     +np.mean(data[:, :, max(0,int(i-0.01*fps)):min(num_frames,int(i+0.01*fps))],2)\n",
    "#                     *1\n",
    "#                     +np.max(data[:, :, max(0,int(i-0.05*fps)):min(num_frames,int(i+0.05*fps))],2)\n",
    "#                     *1\n",
    "#                     * taper)\n",
    "                # using the moving rectangle/square wave block of frames\n",
    "                # instead of by every frame.\n",
    "                # using 0.025*fps, under the assumption of very less vibration frequence above 20hz\n",
    "                # this is seen from fft of xy_shift.\n",
    "                # estimation of these fast vib less than one pixel (most of the cases), so safely disregard them.\n",
    "                \n",
    "        ################define my function above to override the performance.motionshit#####\n",
    "        # f = performance.parallel_motion_shifts  # function to map\n",
    "        raster_phase = (Rastercorrection() & key).fetch1('raster_phase')\n",
    "        fill_fraction = (Scaninfo() & key).fetch1('fill_fraction')\n",
    "        kwargs = {'raster_phase': raster_phase, 'fill_fraction': fill_fraction,\n",
    "                  'template': template}\n",
    "#         os.system(\"taskset -p 0xff %d\" % os.getpid())\n",
    "############################\n",
    "#         chunk_size_in_GB=0.05\n",
    "#         num_processes = mp.cpu_count() - 1\n",
    "#         print('Using', num_processes, 'processes')\n",
    "#         # Calculate the number of frames per chunk\n",
    "        y=slice(skip_rows, -skip_rows)\n",
    "        x=slice(skip_cols, -skip_cols)\n",
    "#         one_frame = scan[field_id, y, x, channel, 0]\n",
    "#         # just one frame so keep using scanreader is fine\n",
    "#         bytes_per_frame = np.prod(one_frame.shape) * 4 # 4 bytes per pixel\n",
    "#         chunk_size = int(round((chunk_size_in_GB * 1024**3) / bytes_per_frame))\n",
    "        num_frames = scan.num_frames\n",
    "        print('num_frames ',num_frames)\n",
    "        thedata=wholescan[skip_rows: -skip_rows, skip_cols: -skip_cols,:]\n",
    "        print('thedata shape3',thedata.shape)\n",
    "#         chunks=[]\n",
    "#         for i in range(0, chunk_size, chunk_size):\n",
    "#             frames = slice(i, min(i + chunk_size, chunk_size))\n",
    "#             thedata=scanfile.asarray(frames)\n",
    "#             thedata=np.swapaxes(thedata,0,2)\n",
    "#             thedata=thedata[skip_rows: -skip_rows, skip_cols: -skip_cols,:]\n",
    "#             chunks.append((thedata))\n",
    "        #############################\n",
    "#         # Create a Queue to put in new chunks and a list for results\n",
    "#         scan_filename=scanreader.core.expand_wildcard(scan_filename)[0]\n",
    "#         scanfile=tifffile.TiffFile(scan_filename)\n",
    "#         # mp init\n",
    "#         manager = mp.Manager()\n",
    "#         chunks = manager.Queue(maxsize=20)\n",
    "#         results = manager.list()\n",
    "#         pool = []\n",
    "#         for i in range(num_processes):\n",
    "# # def the function to call to parallel motion correction\n",
    "# # the args are not ready yet. and function not called yet\n",
    "# #             p = mp.Process(target=performance.parallel_motion_shifts, args=(chunks, results),kwargs=kwargs)\n",
    "#             p = mp.Process(target=ycparallel_motion_shifts, args=(chunks, results),kwargs=kwargs)\n",
    "#             p.start()\n",
    "#             print(p.pid)\n",
    "#             pool.append(p)\n",
    "#         # Produce data\n",
    "#         num_frames = scan.num_frames\n",
    "#         for i in range(0, num_frames, chunk_size):\n",
    "#             frames = slice(i, min(i + chunk_size, num_frames))\n",
    "#             thedata=scanfile.asarray(frames)\n",
    "#             thedata=np.swapaxes(thedata,0,2)\n",
    "#             thedata=thedata[skip_rows: -skip_rows, skip_cols: -skip_cols,:]\n",
    "#             chunks.put((frames,thedata))\n",
    "#         # Queue STOP signal\n",
    "#         for i in range(num_processes):\n",
    "#             chunks.put((None, None))\n",
    "#         # Wait for processes to finish\n",
    "#         for p in pool:\n",
    "#             p.join()\n",
    "\n",
    "#####################\n",
    "#         import tifffile\n",
    "#         scan_filename=scanreader.core.expand_wildcard(scan_filename)[0]\n",
    "#         f=tifffile.TiffFile(scan_filename)\n",
    "#         manager = mp.Manager()\n",
    "#         chunks = manager.Queue(maxsize=20)\n",
    "#         num_frames=200000\n",
    "#         chunk_size=10000\n",
    "#         for i in range(0, num_frames, chunk_size):\n",
    "#             frames = slice(i, min(i + chunk_size, num_frames))\n",
    "#             chunks.put(f.asarray(frames))\n",
    "#############################      \n",
    "#         results = performance.map_frames(f, scan, field_id=field_id,\n",
    "#                                          y=slice(skip_rows, -skip_rows),\n",
    "#                                          x=slice(skip_cols, -skip_cols), channel=channel,\n",
    "#                                          kwargs=kwargs,chunk_size_in_GB=0.005)\n",
    "        # Reduce\n",
    "#         y_shifts = np.zeros(scan.num_frames)\n",
    "#         x_shifts = np.zeros(scan.num_frames)\n",
    "#         for frames, chunk_y_shifts, chunk_x_shifts in results:\n",
    "#             y_shifts[frames] = chunk_y_shifts\n",
    "#             x_shifts[frames] = chunk_x_shifts\n",
    "'''\n",
    "        def postshift(tuple_,key):\n",
    "            if type(tuple_)==dict:\n",
    "                y_shifts=tuple_['y_shifts']\n",
    "                x_shifts=tuple_['x_shifts']\n",
    "            elif type(tuple_)==tuple:\n",
    "                (y_shifts,x_shifts)=tuple_\n",
    "            # Detect outliers\n",
    "            max_y_shift, max_x_shift = 20 / (reso.ScanInfo() & key).microns_per_pixel\n",
    "            y_shifts, x_shifts, outliers = galvo_corrections.fix_outliers(y_shifts, x_shifts,max_y_shift,max_x_shift)\n",
    "            # Center shifts around zero\n",
    "            y_shifts -= np.median(y_shifts)\n",
    "            x_shifts -= np.median(x_shifts)\n",
    "            # Create results tuple\n",
    "            tuple_ = key.copy()\n",
    "            tuple_['field'] = field_id + 1\n",
    "            tuple_['motion_template'] = template\n",
    "            tuple_['y_shifts'] = y_shifts\n",
    "            tuple_['x_shifts'] = x_shifts\n",
    "            tuple_['outlier_frames'] = outliers\n",
    "            tuple_['y_std'] = np.std(y_shifts)\n",
    "            tuple_['x_std'] = np.std(x_shifts)\n",
    "            return tuple_\n",
    "        def mcagain(wholescan,tuple_,fromframe,toframe,method):\n",
    "            wholescan=galvo_corrections.correct_motion(wholescan,tuple_['x_shifts'], tuple_['y_shifts'])\n",
    "            mini_scan=wholescan[:,:,fromframe:toframe] # mini spatially to mini spatially/temporaly\n",
    "            mini_scan = mini_scan.astype(np.float32, copy=False)\n",
    "            mini_scan = 2 * np.sqrt(mini_scan - mini_scan.min() + 3 / 8)\n",
    "            template = np.mean(mini_scan, axis=-1)\n",
    "            template = ndimage.gaussian_filter(template, 0.7)\n",
    "            # define the method used in second motion correction here.\n",
    "            y_shifts2, x_shifts2=yccompute_motion_shifts(wholescan,template,method=method, in_place=True, num_threads=8)\n",
    "            tuple_['x_shifts']=tuple_['x_shifts']+x_shifts2\n",
    "            tuple_['y_shifts']=tuple_['y_shifts']+y_shifts2\n",
    "            return tuple_\n",
    "        # 1st round of motion correction\n",
    "        y_shifts, x_shifts=yccompute_motion_shifts(wholescan,template,method=1, in_place=True, num_threads=8)\n",
    "        tuple_=postshift((y_shifts, x_shifts),key)\n",
    "        tuple_=mcagain(wholescan,tuple_,fromframe,toframe,method=2)\n",
    "        tuple_=postshift(tuple_,key)\n",
    "        ####################################################\n",
    "        # # if use second time motion correction ###################   \n",
    "        # idea is, a typical motion correction way is to use recurrsive till the shifts are below a certain threshold ( mag, std, etc) from articles iv read, about 6-8 times will give a nearly perfect shifts.\n",
    "        # so, im guess running it at least 2 times i would see an improvement. but not significant\n",
    "        # plan is, either using a same, good, method to run multi times, since the method is good, it works better with a sharper template, gives better result\n",
    "        # or, using a high frequncy noise prone method first, get rid of low freq motion to achieve a slighly better template, then a smaller window high temporal resolution method to further correct the rest high freq motion.\n",
    "        # wholescan is the spatially smaller version of full scan, already rastercorrected\n",
    "        # now, correct it with last result.\n",
    "       \n",
    "#         ############################## if more desired.#######\n",
    "#         mc_count=0\n",
    "#         while mc_count>0:\n",
    "#             mc_count-=1\n",
    "#             wholescan=galvo_corrections.correct_motion(wholescan,x_shifts2, y_shifts2)\n",
    "#             mini_scan=wholescan[:,:,fromframe:toframe] # mini spatially to mini spatially/temporaly\n",
    "#             mini_scan = mini_scan.astype(np.float32, copy=False)\n",
    "#             mini_scan = 2 * np.sqrt(mini_scan - mini_scan.min() + 3 / 8)\n",
    "#             template = np.mean(mini_scan, axis=-1)\n",
    "#             print(mc_count,'mc_count, tem shape,', template.shape)\n",
    "#             template = ndimage.gaussian_filter(template, 0.7)\n",
    "#             # define the method used in second motion correction here.\n",
    "#             y_shifts2, x_shifts2=yccompute_motion_shifts(wholescan,template,method=1, in_place=True, num_threads=8)\n",
    "#             print(y_shifts.shape,'shift done. shape')\n",
    "#             x_shifts=x_shifts+x_shifts2\n",
    "#             y_shifts=y_shifts+y_shifts2\n",
    "\n",
    "        # about outliers and shifts\n",
    "        # ideally, the mean of shifts is 0, small amplitude, reasonable frequency\n",
    "        # because vibration generally around the center, avg to 0\n",
    "        # small vibration insteard of large. based on um. around 5 um?\n",
    "        # should be less than 20 hz frequncy?\n",
    "        # tested using a butter low pass filter to apply to shifts, not very good.\n",
    "        # tested fft, 2nd threshold cut off, ifft, even worse.( because of ft edge artifact.)\n",
    "        # maybe because the shift is not good, and filter wont rescue it.\n",
    "        # things to test, find the frequence from ca scan shifts, (better filter), \n",
    "        # Insert\n",
    "        self.insert1(tuple_)\n",
    "        # Notify after all fields have been processed\n",
    "        scan_key = {'animal_id': key['animal_id'], 'session': key['session'],\n",
    "                    'scan_idx': key['scan_idx'], 'pipe_version': key['pipe_version']}\n",
    "        if len(Motioncorrection - Scaninfo & scan_key) > 0:\n",
    "            self.notify(scan_key, scan.num_frames, scan.num_fields)\n",
    "            \n",
    "    @notify.ignore_exceptions\n",
    "    def notify(self, key, num_frames, num_fields):\n",
    "        fps = (Scaninfo() & key).fetch1('fps')\n",
    "        seconds = np.arange(num_frames) / fps\n",
    "        fig, axes = plt.subplots(num_fields, 1, figsize=(15, 4 * num_fields), sharey=True)\n",
    "        axes = [axes] if num_fields == 1 else axes # make list if single axis object\n",
    "        for i in range(num_fields):\n",
    "            y_shifts, x_shifts = (self & key & {'field': i + 1}).fetch1('y_shifts',\n",
    "                                                                        'x_shifts')\n",
    "            axes[i].set_title('Shifts for field {}'.format(i + 1))\n",
    "            axes[i].plot(seconds, y_shifts, label='y shifts')\n",
    "            axes[i].plot(seconds, x_shifts, label='x shifts')\n",
    "            axes[i].set_ylabel('Pixels')\n",
    "            axes[i].set_xlabel('Seconds')\n",
    "            axes[i].legend()\n",
    "        fig.tight_layout()\n",
    "        img_filename = '/tmp/' + key_hash(key) + '.png'\n",
    "        fig.savefig(img_filename, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        msg = 'motion shifts for {animal_id}-{session}-{scan_idx}'.format(**key)\n",
    "        slack_user = notify.SlackUser() & (experiment.Session() & key)\n",
    "        slack_user.notify(file=img_filename, file_title=msg)\n",
    "   \n",
    "    def get_correct_motionf(self):\n",
    "        \"\"\" Returns a function to perform motion correction on scans. \"\"\"\n",
    "        import scipy\n",
    "        x_shifts, y_shifts = self.fetch1('x_shifts', 'y_shifts')\n",
    "        b, a = scipy.signal.butter(4, 20, 'low',fs=400)\n",
    "        x_shifts=scipy.signal.lfilter(b,a,x_shifts)\n",
    "        y_shifts=scipy.signal.lfilter(b,a,y_shifts)\n",
    "        return lambda scan, indices=slice(None): galvo_corrections.correct_motion(scan,\n",
    "                                                 x_shifts[indices], y_shifts[indices])\n",
    "    def get_correct_motion(self):\n",
    "        \"\"\" Returns a function to perform motion correction on scans. \"\"\"\n",
    "        x_shifts, y_shifts = self.fetch1('x_shifts', 'y_shifts')\n",
    "        return lambda scan, indices=slice(None): galvo_corrections.correct_motion(scan,\n",
    "                                                 x_shifts[indices], y_shifts[indices])\n",
    "\n",
    "    def getvideo(self,fname,filter=False):\n",
    "        correct_raster = (Rastercorrection()&self).get_correct_raster()\n",
    "        if filter:\n",
    "            correct_motion = self.get_correct_motionf()\n",
    "        else:\n",
    "            correct_motion = self.get_correct_motion()\n",
    "        nchan=(Scaninfo()&self).fetch1('nchannels')\n",
    "        fps=(Scaninfo()&self).fetch1('fps')\n",
    "        dim=((Scaninfo()&self).fetch1('px_width'),(Scaninfo()&self).fetch1('px_height'))\n",
    "        f=tifffile.TiffFile(scanreader.core.expand_wildcard((experiment.Scan() & self ).local_filenames_as_wildcard)[0])\n",
    "        wholecan=f.asarray()\n",
    "        wholecan=np.moveaxis(wholecan,0,2)\n",
    "        wholecan=wholecan[:,:,::nchan]\n",
    "        num_frames=(Scaninfo()&self).fetch1('nframes')\n",
    "        savevideo(fps,dim,num_frames,correct_motion(correct_raster(wholecan)),\n",
    "                  video_filename=fname)\n",
    "    def savevideo(fps,dim,num_frames,clipdata,video_filename='original.avi'):\n",
    "        fourcc=cv2.VideoWriter_fourcc('M',\"J\",\"P\",\"G\")\n",
    "        out=cv2.VideoWriter(video_filename,fourcc,fps,dim)\n",
    "        for i in range(num_frames):\n",
    "            ardata=cv2.normalize(clipdata[:, :, i],None,255,0,norm_type=cv2.NORM_MINMAX,dtype=cv2.CV_8U)\n",
    "            ardata3c=cv2.merge([ardata,ardata,ardata])\n",
    "            out.write(ardata3c)\n",
    "        out.release()\n",
    "\n",
    "@patchtable\n",
    "class Segmentation(dj.Manual):\n",
    "    definition = \"\"\" \n",
    "        ->Motioncorrection\n",
    "        # segmentation task\n",
    "        ---\n",
    "        time:timestamp\n",
    "        \"\"\"\n",
    "#     class Mask(dj.Part):\n",
    "#         definition = \"\"\" \n",
    "#         -> Segmentation\n",
    "#         mask_id         : smallint\n",
    "#         ---\n",
    "#         pixels          : longblob      # indices into the image in column major (Fortran) order\n",
    "#         weights         : longblob      # weights of the mask at the indices above\n",
    "#         \"\"\"\n",
    "#     class Method1(dj.Part):\n",
    "#         definition = \"\"\" \n",
    "#         ->Segmentation\n",
    "#         ---\n",
    "#         paramenter:int\n",
    "#         \"\"\"\n",
    "@patchtable\n",
    "class Trace(dj.Manual):\n",
    "    definition = \"\"\" \n",
    "        ->Segmentation\n",
    "        ---\n",
    "        trace:external\n",
    "    \"\"\"  \n",
    "@patchtable\n",
    "class Tracespikes(dj.Manual):\n",
    "    definition = \"\"\" \n",
    "        ->Trace\n",
    "        ---\n",
    "        spikets:external\n",
    "    \"\"\"\n",
    "# combining primary keys\n",
    "@patchtable\n",
    "class Ephys2p(dj.Manual):\n",
    "    definition = \"\"\" \n",
    "        ->Recording\n",
    "        ->Segmentation\n",
    "        ---\n",
    "        \n",
    "    \"\"\" \n",
    "    @property\n",
    "    def key_source(self):\n",
    "        return Recording()# & {'pipe_version': CURRENT_VERSION}\n",
    "        # only using the key from xxx() to find the key in other tb\n",
    "    \n",
    "# dj.ERD(patchtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time Rastercorrection.populate()\n",
    "# %time Motioncorrection.populate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scaninfokeys=(reso.ScanInfo() & {'animal_id':20053,'session':3,'scan_idx':1}).fetch1()\n",
    "\n",
    "\n",
    "correctionchkeys=(reso.CorrectionChannel() & {'animal_id':20053,'session':3,'scan_idx':1}).fetch1()\n",
    "scaninfokeys['channel']=correctionchkeys['channel']\n",
    "scaninfokeys['field']=correctionchkeys['field']\n",
    "fieldkeys=(reso.ScanInfo.Field() & {'animal_id':20053,'session':3,'scan_idx':1}).fetch1()\n",
    "scaninfokeys['z']=fieldkeys['z']\n",
    "scaninfokeys['delay_image']=fieldkeys['delay_image']\n",
    "\n",
    "\n",
    "Scaninfo.insert1(scaninfokeys,skip_duplicates=True)\n",
    "\n",
    "Rastercorrection.populate()\n",
    "Rastercorrection().fetch1()\n",
    "Scaninfo().fetch1('fps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y[1000:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compkey={'animal_id':18252,'session':2,'scan_idx':27}\n",
    "\n",
    "cy=(reso.MotionCorrection()&compkey).fetch1('y_shifts')\n",
    "cfps=(reso.ScanInfo()&compkey).fetch1('fps')\n",
    "secax=list(range(len(cy)))/cfps\n",
    "plt.plot(secax[1000:1100],cy[1000:1100])\n",
    "cfps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motiontraceplot(fromto):\n",
    "    x=Motioncorrection().fetch1('x_shifts')\n",
    "    fps=Scaninfo().fetch1('fps')\n",
    "    secunitaxis=list(range(len(x)))/fps\n",
    "    plt.plot(secunitaxis[fromto[0]:fromto[1]],x[fromto[0]:fromto[1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motiontraceplot([0,1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(chunk[:, :, i])\n",
    "plt.imshow(np.fft.fftshift(abs(ifft(fft(chunk[:, :, i])*template_freq))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(chunk[:, :, 100:int(100+.05*fps)],2))\n",
    "chunk[:, :, 100:int(100+fps)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(shifted_cross_power), shifted_cross_power.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(np.argmax(shifted_cross_power), shifted_cross_power.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "plt.imshow(abs(np.log(1+fft(chunk[:, :, i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanreader.core.expand_wildcard((experiment.Scan() & (reso.ScanInfo & 'fps>20').fetch('KEY')[3]).local_filenames_as_wildcard)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key={'animal_id':20053,'session':3,'scan_idx':1}\n",
    "correct_raster = (Rastercorrection()).get_correct_raster()\n",
    "correct_motion = (Motioncorrection() ).get_correct_motion()\n",
    "f=tifffile.TiffFile(scanreader.core.expand_wildcard((experiment.Scan() & key).local_filenames_as_wildcard)[0])\n",
    "wholecan=f.asarray()\n",
    "wholecan=np.swapaxes(wholecan,0,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(wholecan[:,:,10000:13000],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcrez=np.mean((correct_raster(wholecan)),2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rcrez,vmin=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcrez=(correct_motion(correct_raster(wholecan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mcrez*mcrez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((mcrez-rcrez)[2:-2,2:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subrez=np.subtract(   (correct_motion(correct_raster(wholecan))), (correct_raster(wholecan))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(subrez[1:-1,1:-1,8000:10000],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(mcrez,2), vmin=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n=np.where((np.mean(mcrez,2))>90)\n",
    "\n",
    "\n",
    "zeroarry=np.zeros(mcrez.shape)\n",
    "for mm,nn in zip(m,n):\n",
    "    zeroarry[mm,nn,:]=mcrez[mm,nn,:]\n",
    "             #now zeroarry is like a neuron\n",
    "        # can extract trace\n",
    "# plt.imshow(zeroarry[:,:,3])\n",
    "\n",
    "trace=[]\n",
    "for frames in range(mcrez.shape[-1]):\n",
    "    trace.append(np.mean(zeroarry[:,:,frames]))\n",
    "    \n",
    "plt.imshow(np.mean(zeroarry,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(50,20))\n",
    "plt.plot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5\n",
    "trace=np.asarray(trace)\n",
    "data=h5.readephys('oneCell10_0.h5')\n",
    "patchcell={}\n",
    "patchcell['depth']=190\n",
    "patchcell['power']=60\n",
    "vt = h5.ts2sec(data['data']['ts'], is_packeted=True)\n",
    "vm=data['data']['v1']\n",
    "peaks=(np.diff(data['data']['scanImage']))\n",
    "peaks2=np.argwhere((np.diff(data['data']['scanImage'])) > 2.495)\n",
    "ft=vt[peaks2]\n",
    "patchcell['frametimes']=ft\n",
    "patchcell['ephystimes']=vt\n",
    "patchcell['vm']=vm*1000\n",
    "patchcell['trace']=trace\n",
    "fig=plt.figure(figsize=(50,20))\n",
    "plt.plot(patchcell['ephystimes'],patchcell['vm']*10,alpha=0.8)\n",
    "plt.plot(patchcell['frametimes'],patchcell['trace'],alpha=0.8)\n",
    "plt.scatter(patchcell['ephystimes'][firstspkindex],patchcell['vm'][firstspkindex]*10,color = 'r',s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchcell['trace']=(trace-np.mean(trace))*(trace-np.mean(trace))-np.mean(patchcell['vm']*10)\n",
    "fig=plt.figure(figsize=(50,20))\n",
    "plt.plot(patchcell['ephystimes'],patchcell['vm']*10,alpha=0.8)\n",
    "plt.plot(patchcell['frametimes'],patchcell['trace'],alpha=0.8)\n",
    "plt.scatter(patchcell['ephystimes'][firstspkindex],patchcell['vm'][firstspkindex]*10,color = 'r',s=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "rez=butter_bandpass_filter(trace,5.0,30,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(50,20))\n",
    "plt.plot(patchcell['frametimes'],patchcell['trace'],alpha=0.8)\n",
    "plt.plot(patchcell['frametimes'],rez,alpha=0.8)\n",
    "# for i in patchcell['ephystimes'][firstspkindex]:\n",
    "#         plt.axvline(x=i,ymin=0,ymax=10,color = 'r',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(50,20))\n",
    "plt.plot(patchcell['ephystimes'],patchcell['vm']*10,alpha=0.8)\n",
    "# plt.plot(patchcell['frametimes'],patchcell['trace'],alpha=0.8)\n",
    "plt.scatter(patchcell['ephystimes'][firstspkindex],patchcell['vm'][firstspkindex]*10,color = 'r',s=10)\n",
    "plt.plot(patchcell['frametimes'],rez*15+40,alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(50,20))\n",
    "plt.plot(patchcell['ephystimes'][4000000:4030000],patchcell['vm'][4000000:4030000]*10,alpha=0.8)\n",
    "# plt.plot(patchcell['frametimes'],patchcell['trace'],alpha=0.8)\n",
    "plt.scatter(patchcell['ephystimes'][firstspkindex][4000000:4030000],patchcell['vm'][firstspkindex][4000000:4030000]*10,color = 'r',s=20)\n",
    "plt.plot(patchcell['frametimes'][130700:132000],rez[130700:132000]*15+20,alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(patchcell['frametimes'][130000:130100],alpha=0.8)\n",
    "plt.plot(list(range(patchcell['frametimes'][130000],patchcell['frametimes'][130100]),alpha=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchcell['frametimes'][130100]-patchcell['frametimes'][130000]\n",
    "data:image/png;base64,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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtt = h5.ts2sec(data['data']['ts'], is_packeted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vtt[1:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(trace,bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reso.Activity.Trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipkey=(reso.ScanInfo & 'fps>300').fetch('KEY')[1]\n",
    "clipkey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newt=(reso.Activity.Trace & clipkey).fetch('trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(newt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(newt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to exp decay\n",
    "# plot hist, decidce threshold\n",
    "# thresholding, add some regulation about timing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rastercorrection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Motioncorrection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
